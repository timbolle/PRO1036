---
title: "Lab 09 - Hotel Bookings ?"
---

```{r include = FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
  out.width = "80%",
  fig.asp = 0.618,
  fig.width = 10,
  dpi = 300
)
```

# Introduction

Dans ce lab, nous allons travailler sur un jeu de données qui contient des informations sur des réservations d'hôtels. Nous allons essayer de prédire si une réservation avait des enfants. Pour cela, nous allons utiliser des méthodes de classification.

# Préparation des données

## Chargement des données


```{r, message=FALSE, warning=FALSE}
library(tidymodels)
library(readr)

hotels <- 
  read_csv("https://tidymodels.org/start/case-study/hotels.csv") %>%
  mutate(across(where(is.character), as.factor))

dim(hotels)
```

Nous pouvons jeter un coup d'oeil aux données:

```{r, message=FALSE}
glimpse(hotels)
```

*Question 1*: Déterminez la proportio de réservations qui ont des enfants.

# Séparation des données

Commencez par diviser les données en un ensemble d'entraînement et un ensemble de test. Utilisez 75% des données pour l'entraînement. Assurez-vous que les proportions de réservations avec enfants sont les mêmes dans les deux ensembles.

```{r, echo=FALSE}
set.seed(123)
splits      <- initial_split(hotels, strata = children)

hotel_train <- training(splits)
hotel_test  <- testing(splits)
```

Dans cet exemple, nous avons un nombre important de données. Il est donc assez probable que les données utilisées pour l'entrainement soient représentatives de l'ensemble des données. Nous n'allons donc pas utiliser de validation croisée (avec 10 rééchantillonages). Nous allons simplement séparer les données entrainement en un ensemble d'entrainement et un ensemble de validation.

Pour cela, utilisez la fonction `validation_split` pour diviser les données d'entrainement en deux ensembles: un ensemble d'entrainement et un ensemble de validation. Utilisez 80% des données pour l'entrainement.

Au final, nous aurons donc trois ensembles de données: 

  - un ensemble d'entrainement (60% des données initiales)
  - un ensemble de validation (15% des données initiales)
  - un ensemble de test. (25% des données initiales)
  
```{r, echo=FALSE}
val_set <- validation_split(hotel_train, 
                            strata = children, 
                            prop = 0.80)
```


# Premier Modèle: Régression logistique

Nous cherchons à déterminer si une réservation a des enfants. Il s'agit d'un problème de classification binaire. Nous allons commencer par utiliser une régression logistique.

## Construction du modèle

Configurez un modèle de regression logistique en utilisant la fonction `logistic_reg()`. Utilisez la fonction `set_engine()` pour spécifier que vous voulez utiliser la fonction `glm()`.

```{r, echo=FALSE}
logistic_spec <- 
  logistic_reg() %>%
  set_engine("glm")
```

## Création d'une recette

Créez une recette pour le modèle en utilisant la fonction `recipe()`.

Nous allons utiliser les recettes suivantes:

  - `step_date()`: pour créer les variable de l'année, du mois et du jour de la semaine
  - `step_holiday()`: pour créer une variable qui indique si la réservation a été faite pendant une période de vacances. Nous vous avons fourni une liste de vacances dans le fichier de réponse (voir ci-dessous). Vous pouvez indiquer d'utiliser cette liste avec `step_holiday(arrival_date, holidays = holidays)`
  - `step_rm()`: pour supprimer les variables `arrival_date`
  
Nous allons également transformer les variables catégorielles en _dummy variables_ et les variables numériques en variables centrées et réduites.

  - `step_dummy()` pour convertir les variables catégorielles (`all_nominal_predictors()`) en variables binaires
  - `step_zv()` permet d'enlever les variables qui ne contiennent qu'une unique valeur (`all_predictors()`)
  - `step_normalize()` pour centrer et réduire les variables numériques (`all_numeric_predictors()`)
  

```{r, echo=FALSE}
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe <- 
  recipe(children ~ ., data = hotel_train) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date, holidays = holidays) %>% 
  step_rm(arrival_date) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())
```

```{r, eval=FALSE}
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe <- 
  recipe(________, data = hotel_train) %>% 
  step_date(____) %>% 
  step_XXXXX(______, _______) %>% 
  step_XXXXX(_____) %>% 
  _____
```


## Création du `workflow`

Créez un `workflow` en utilisant la fonction `workflow()`. Ajoutez-y la recette et le modèle.

```{r, echo=FALSE}
lr_workflow <- 
  workflow() %>% 
  add_recipe(lr_recipe) %>% 
  add_model(logistic_spec)
```


## Entrainement du modèle

Entraînez le modèle en utilisant la fonction `fit()`.


```{r, echo=FALSE}
lr_fit <- lr_workflow %>% 
  fit(data = hotel_train)
```
## Évaluation du modèle

Utilisez la fonction `predict()` pour obtenir les prédictions du modèle sur l'ensemble de validation.


```{r}
lr_pred <- predict(lr_fit, hotel_test) %>%
  bind_cols(predict(lr_fit, hotel_test, type = "prob")) %>%
  bind_cols(hotel_test %>% select(children))
  
```

Générez une courbe ROC pour évaluer le modèle.

```{r, echo=FALSE}
lr_auc <- lr_pred %>%
  roc_curve(children, .pred_children) %>%
  mutate(model = "Logistic Regression")

lr_auc %>% autoplot()
```


# Deuxième modèle: Random Forest

Nous allons maintenant essayer un modèle de Random Forest. Il s'agit d'un modèle plus complexe que la régression logistique. Le Random Forest est un modèle ensembliste qui combine plusieurs arbres de décision.

## Construction du modèle

Nous allons utiliser le modèle suivant:

```{r}
cores <- parallel::detectCores() # Nombre de coeur à disposition pour le calcul

rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_engine("ranger", num.threads = cores) %>% 
  set_mode("classification")
```

Nous avons deux paramètre à otpimiser: `mtry` et `min_n`. Nous allons utiliser la fonction `tune_grid()` pour optimiser ces paramètres.

## Création d'une recette

La recette pour ce modèle est un peu plus simple que pour la régression logistique. Vous pouvez utiliser la recette suivante:

```{r}
rf_recipe <- 
  recipe(children ~ ., data = hotel_train) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date) %>% 
  step_rm(arrival_date) 
```

Créez un workflow pour ce modèle, qui contient la recette et le modèle.

```{r, echo=FALSE}
rf_workflow <- 
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(rf_recipe)
```

## Optimisation des paramètres

Le paramètre `mtry` est le nombre de variables à considérer à chaque division d'un noeud. il est donc compris entre 1 et le nombre de variable. Le paramètre `min_n` est le nombre minimum d'observations dans un noeud terminal.

Créez une grille de recherche pour ces paramètres. Faites en sorte que `mtry` prenne 5 valeurs différentes et que `min_n` prenne 5 valeurs différentes également, pour un total de 25 combinaisons. Comme le paramètre `mtry`dépend du nombre de variables, il faut lui préciser les bornes manuellement. Le nombre de colonne peut être obtenu à l'aide de la fonction suivante:

```{r}
n_col <- prep(rf_recipe) %>% juice() %>% ncol()
```

Il est ensuite possible de préciser la range avec `mtry(range = c(1, n_col - 1))`.

```{r, echo=FALSE}
rf_grid <- 
  grid_regular(mtry(range = c(1, n_col - 1)),
               min_n(),
               levels = 3)
```

Nous pouvons maintenant faire une recherche de grille pour trouver les meilleurs paramètres. Nous allons utiliser la fonction `tune_grid()` pour cela. Le set de validation est utiliser pour trouver la meilleure combinaison.

```{r}
rf_res <- 
  rf_workflow %>% 
  tune_grid(val_set,
            grid =  rf_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```


## Choix des paramètres et Évaluation de la performance

On peut maintenant voir quelle est la meilleure combinaison de paramètres.

```{r}
rf_res %>% 
  show_best(metric = "roc_auc")
```

La fonction `autoplot()` permet de visualiser les résultats de la recherche de grille.

```{r}
rf_res %>% 
  autoplot()
```

Nous pouvons garder les meilleures paramètres:

```{r}
rf_best <- 
  rf_res %>% 
  select_best(metric = "roc_auc")
```


Nous pouvons maintenant générer une courbe ROC et la comparer à celle obtenue précédemment.

```{r}
rf_auc <- 
  rf_res %>% 
  collect_predictions(parameters = rf_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Random Forest")
```


```{r}
bind_rows(rf_auc, lr_auc) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)
```


